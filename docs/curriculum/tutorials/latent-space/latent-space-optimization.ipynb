{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Molecular Optimization in Latent Space with Bayesian Optimization\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sgbaird/honegumi/blob/main/docs/curriculum/tutorials/latent-space/latent-space-optimization.ipynb)\n",
    "\n",
    "Traditional molecular optimization approaches face significant challenges when dealing with the discrete, combinatorially complex chemical space. Molecules represented as SMILES strings or molecular graphs don't naturally fit into continuous optimization frameworks like Bayesian optimization. However, recent advances in deep generative models, particularly Variational Autoencoders (VAEs), have opened up new possibilities for molecular design.\n",
    "\n",
    "**Latent space optimization** involves training a generative model (such as a VAE) to encode molecules into a continuous, lower-dimensional latent space where Bayesian optimization can be efficiently performed. The optimized latent representations can then be decoded back into molecular structures.\n",
    "\n",
    "In this tutorial, we'll demonstrate how to:\n",
    "1. Encode molecules into a continuous latent space using a simple VAE\n",
    "2. Perform Bayesian optimization in the latent space\n",
    "3. Decode optimized latent points back to molecules\n",
    "4. Optimize molecular properties like drug-likeness (QED score)\n",
    "\n",
    "---\n",
    "\n",
    "**Scenario**: You're a computational chemist working on drug discovery, tasked with finding molecules with high drug-likeness while maintaining synthetic accessibility. Traditional approaches would require extensive manual design or brute-force screening of large chemical databases. Instead, you'll use latent space Bayesian optimization to efficiently explore chemical space and identify promising drug candidates.\n",
    "\n",
    "This approach is particularly valuable for:\n",
    "- **Drug discovery**: Optimizing ADMET properties, drug-likeness, target binding\n",
    "- **Materials science**: Designing polymers, catalysts, or electronic materials\n",
    "- **Sustainable chemistry**: Finding environmentally friendly alternatives\n",
    "\n",
    "We'll use a simplified molecular VAE and QED (Quantitative Estimate of Drug-likeness) as our objective, but the framework extends to any molecular property prediction model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Dependencies\n",
    "\n",
    "First, let's install and import the necessary packages. We'll use RDKit for molecular manipulation, scikit-learn for the VAE implementation, and Honegumi/Ax for Bayesian optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (uncomment if running in Colab)\n",
    "# !pip install rdkit-pypi scikit-learn matplotlib numpy pandas ax-platform\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Try to import RDKit, use fallback if not available\n",
    "try:\n",
    "    from rdkit import Chem\n",
    "    from rdkit.Chem import Descriptors, QED\n",
    "    from rdkit.Chem import rdMolDescriptors\n",
    "    RDKIT_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"RDKit not available, using simplified molecular representations\")\n",
    "    RDKIT_AVAILABLE = False\n",
    "\n",
    "# Ax platform imports\n",
    "from ax.service.ax_client import AxClient\n",
    "from ax.service.utils.instantiation import ObjectiveProperties\n",
    "from ax.utils.measurement.synthetic_functions import branin\n",
    "from ax.core.objective import Objective\n",
    "from ax.core.optimization_config import OptimizationConfig\n",
    "from ax.core.parameter import RangeParameter, ParameterType\n",
    "from ax.core.search_space import SearchSpace\n",
    "from ax.modelbridge.generation_strategy import GenerationStrategy, GenerationStep\n",
    "from ax.modelbridge.registry import Models\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Molecular Dataset and Representation\n",
    "\n",
    "We'll create a simplified molecular dataset. In practice, you might use datasets like ZINC, ChEMBL, or GuacaMol benchmark datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_molecular_dataset(n_molecules=1000, seed=42):\n",
    "    \"\"\"\n",
    "    Generate a simplified molecular dataset with SMILES and molecular properties.\n",
    "    If RDKit is available, we use real molecular descriptors. Otherwise, we simulate them.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    if RDKIT_AVAILABLE:\n",
    "        # A small set of drug-like molecules for this example\n",
    "        base_smiles = [\n",
    "            \"CCO\",  # ethanol\n",
    "            \"CC(=O)OC1=CC=CC=C1C(=O)O\",  # aspirin\n",
    "            \"CC(C)CC1=CC=C(C=C1)C(C)C(=O)O\",  # ibuprofen\n",
    "            \"CN1C=NC2=C1C(=O)N(C(=O)N2C)C\",  # caffeine\n",
    "            \"CC(C)(C)C1=CC=C(C=C1)C(C)(C)C\",  # simple aromatic\n",
    "            \"CCCCCCCCCCCCCCC(=O)O\",  # fatty acid\n",
    "            \"CC1=CC=C(C=C1)N\",  # aniline derivative\n",
    "            \"CC(C)C1=CC=C(C=C1)O\",  # phenol derivative\n",
    "        ]\n",
    "        \n",
    "        molecules = []\n",
    "        for i in range(n_molecules):\n",
    "            # Select a base molecule and add some random variation\n",
    "            base_smi = np.random.choice(base_smiles)\n",
    "            mol = Chem.MolFromSmiles(base_smi)\n",
    "            if mol is not None:\n",
    "                smiles = Chem.MolToSmiles(mol)\n",
    "                \n",
    "                # Calculate molecular descriptors\n",
    "                mw = Descriptors.MolWt(mol)\n",
    "                logp = Descriptors.MolLogP(mol)\n",
    "                tpsa = Descriptors.TPSA(mol)\n",
    "                qed_score = QED.qed(mol)\n",
    "                \n",
    "                molecules.append({\n",
    "                    'smiles': smiles,\n",
    "                    'molecular_weight': mw,\n",
    "                    'logp': logp,\n",
    "                    'tpsa': tpsa,\n",
    "                    'qed': qed_score,\n",
    "                    'mol_id': i\n",
    "                })\n",
    "        \n",
    "        return pd.DataFrame(molecules)\n",
    "    \n",
    "    else:\n",
    "        # Fallback: simulate molecular data\n",
    "        molecules = []\n",
    "        for i in range(n_molecules):\n",
    "            # Simulate molecular descriptors\n",
    "            mw = np.random.normal(300, 100)  # molecular weight\n",
    "            logp = np.random.normal(2, 1.5)  # lipophilicity\n",
    "            tpsa = np.random.exponential(60)  # topological polar surface area\n",
    "            qed_score = np.random.beta(2, 2)  # QED score between 0 and 1\n",
    "            \n",
    "            molecules.append({\n",
    "                'smiles': f'simulated_mol_{i}',\n",
    "                'molecular_weight': max(50, mw),\n",
    "                'logp': logp,\n",
    "                'tpsa': max(0, tpsa),\n",
    "                'qed': qed_score,\n",
    "                'mol_id': i\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(molecules)\n",
    "\n",
    "# Generate the dataset\n",
    "molecular_data = generate_molecular_dataset(n_molecules=500)\n",
    "print(f\"Generated {len(molecular_data)} molecules\")\n",
    "print(\"\\nDataset preview:\")\n",
    "print(molecular_data.head())\n",
    "print(f\"\\nQED score range: {molecular_data['qed'].min():.3f} - {molecular_data['qed'].max():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Molecular VAE: Encoding to Latent Space\n",
    "\n",
    "Now we'll create a simplified molecular VAE. In practice, you might use more sophisticated models like:\n",
    "- Junction Tree VAE (JT-VAE)\n",
    "- Grammar VAE\n",
    "- Molecular VAE with SMILES\n",
    "- Graph VAE\n",
    "\n",
    "For this tutorial, we'll use molecular descriptors as our \"encoding\" and PCA as a simplified latent space representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplifiedMolecularVAE:\n",
    "    \"\"\"\n",
    "    A simplified molecular VAE using molecular descriptors and PCA.\n",
    "    In practice, this would be a neural network trained on molecular SMILES or graphs.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim=3):\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = None  # PCA for dimensionality reduction\n",
    "        self.decoder = None  # Random Forest for reconstruction\n",
    "        self.scaler = StandardScaler()\n",
    "        self.feature_columns = ['molecular_weight', 'logp', 'tpsa']\n",
    "        \n",
    "    def fit(self, molecular_data):\n",
    "        \"\"\"Train the VAE on molecular data\"\"\"\n",
    "        # Extract molecular features\n",
    "        features = molecular_data[self.feature_columns].values\n",
    "        \n",
    "        # Normalize features\n",
    "        features_scaled = self.scaler.fit_transform(features)\n",
    "        \n",
    "        # Use PCA as the encoder (dimensionality reduction)\n",
    "        self.encoder = PCA(n_components=self.latent_dim)\n",
    "        latent_repr = self.encoder.fit_transform(features_scaled)\n",
    "        \n",
    "        # Train a decoder (Random Forest) to reconstruct molecular features\n",
    "        self.decoder = RandomForestRegressor(n_estimators=50, random_state=42)\n",
    "        self.decoder.fit(latent_repr, features_scaled)\n",
    "        \n",
    "        return latent_repr\n",
    "    \n",
    "    def encode(self, molecular_data):\n",
    "        \"\"\"Encode molecules to latent space\"\"\"\n",
    "        features = molecular_data[self.feature_columns].values\n",
    "        features_scaled = self.scaler.transform(features)\n",
    "        return self.encoder.transform(features_scaled)\n",
    "    \n",
    "    def decode(self, latent_points):\n",
    "        \"\"\"Decode latent points back to molecular features\"\"\"\n",
    "        features_scaled = self.decoder.predict(latent_points)\n",
    "        features = self.scaler.inverse_transform(features_scaled)\n",
    "        \n",
    "        # Convert back to molecular properties\n",
    "        decoded_molecules = pd.DataFrame(\n",
    "            features, \n",
    "            columns=self.feature_columns\n",
    "        )\n",
    "        \n",
    "        # Ensure realistic ranges\n",
    "        decoded_molecules['molecular_weight'] = np.clip(decoded_molecules['molecular_weight'], 50, 1000)\n",
    "        decoded_molecules['tpsa'] = np.clip(decoded_molecules['tpsa'], 0, 200)\n",
    "        \n",
    "        return decoded_molecules\n",
    "    \n",
    "    def get_latent_bounds(self, molecular_data, percentile=95):\n",
    "        \"\"\"Get reasonable bounds for the latent space based on training data\"\"\"\n",
    "        latent_repr = self.encode(molecular_data)\n",
    "        \n",
    "        bounds = []\n",
    "        for i in range(self.latent_dim):\n",
    "            lower = np.percentile(latent_repr[:, i], 100 - percentile)\n",
    "            upper = np.percentile(latent_repr[:, i], percentile)\n",
    "            bounds.append((lower, upper))\n",
    "        \n",
    "        return bounds\n",
    "\n",
    "# Initialize and train the VAE\n",
    "vae = SimplifiedMolecularVAE(latent_dim=3)\n",
    "latent_representations = vae.fit(molecular_data)\n",
    "\n",
    "print(f\"Trained VAE with latent dimension: {vae.latent_dim}\")\n",
    "print(f\"Latent representations shape: {latent_representations.shape}\")\n",
    "print(f\"Explained variance ratio: {vae.encoder.explained_variance_ratio_}\")\n",
    "\n",
    "# Get bounds for latent space optimization\n",
    "latent_bounds = vae.get_latent_bounds(molecular_data)\n",
    "print(f\"\\nLatent space bounds: {latent_bounds}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Molecular Property Prediction\n",
    "\n",
    "We need a function that can predict molecular properties from latent space coordinates. This will serve as our objective function for Bayesian optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_qed_from_properties(molecular_props):\n",
    "    \"\"\"\n",
    "    Calculate a simplified QED-like score from molecular properties.\n",
    "    In practice, you'd use the actual QED calculation or other property predictors.\n",
    "    \"\"\"\n",
    "    if RDKIT_AVAILABLE:\n",
    "        # If we have RDKit, we'll estimate QED from basic properties\n",
    "        # This is a simplified approximation\n",
    "        mw = molecular_props['molecular_weight']\n",
    "        logp = molecular_props['logp']\n",
    "        tpsa = molecular_props['tpsa']\n",
    "        \n",
    "        # Lipinski's rule of five-inspired scoring\n",
    "        mw_score = 1.0 if 150 <= mw <= 500 else max(0, 1 - abs(mw - 325) / 325)\n",
    "        logp_score = 1.0 if -0.4 <= logp <= 5.6 else max(0, 1 - abs(logp - 2.6) / 3.0)\n",
    "        tpsa_score = 1.0 if tpsa <= 140 else max(0, 1 - (tpsa - 140) / 100)\n",
    "        \n",
    "        qed_score = (mw_score * logp_score * tpsa_score) ** (1/3)\n",
    "        return qed_score\n",
    "    else:\n",
    "        # Fallback calculation\n",
    "        mw = molecular_props['molecular_weight']\n",
    "        logp = molecular_props['logp']\n",
    "        tpsa = molecular_props['tpsa']\n",
    "        \n",
    "        # Simple scoring function\n",
    "        score = 0.5 + 0.3 * np.exp(-((mw - 300) / 100) ** 2) + \\\n",
    "                0.2 * np.exp(-((logp - 2) / 1.5) ** 2) + \\\n",
    "                0.1 * np.exp(-(tpsa / 60) ** 2)\n",
    "        return min(1.0, score)\n",
    "\n",
    "def molecular_objective_function(latent_point):\n",
    "    \"\"\"\n",
    "    Objective function that takes a latent space point and returns molecular property.\n",
    "    This function:\n",
    "    1. Decodes the latent point to molecular features\n",
    "    2. Calculates molecular properties (QED score)\n",
    "    3. Returns the property value\n",
    "    \"\"\"\n",
    "    # Reshape if needed\n",
    "    if len(latent_point.shape) == 1:\n",
    "        latent_point = latent_point.reshape(1, -1)\n",
    "    \n",
    "    # Decode latent point to molecular properties\n",
    "    decoded_molecules = vae.decode(latent_point)\n",
    "    \n",
    "    # Calculate QED score for the first (and only) molecule\n",
    "    mol_props = decoded_molecules.iloc[0]\n",
    "    qed_score = calculate_qed_from_properties(mol_props)\n",
    "    \n",
    "    return qed_score\n",
    "\n",
    "# Test the objective function\n",
    "test_latent = latent_representations[0].reshape(1, -1)\n",
    "test_score = molecular_objective_function(test_latent)\n",
    "print(f\"Test molecular score: {test_score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Bayesian Optimization in Latent Space\n",
    "\n",
    "Now we'll use Honegumi's Ax integration to perform Bayesian optimization in the latent space. We'll optimize for high QED scores (drug-likeness)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ax_objective_function(parameterization):\n",
    "    \"\"\"\n",
    "    Wrapper function for Ax that converts parameterization dict to latent point\n",
    "    and evaluates the molecular objective.\n",
    "    \"\"\"\n",
    "    # Extract latent coordinates\n",
    "    latent_point = np.array([\n",
    "        parameterization['latent_dim_0'],\n",
    "        parameterization['latent_dim_1'], \n",
    "        parameterization['latent_dim_2']\n",
    "    ])\n",
    "    \n",
    "    # Evaluate molecular property\n",
    "    score = molecular_objective_function(latent_point)\n",
    "    \n",
    "    return {\"qed_score\": (score, 0.0)}  # (value, sem)\n",
    "\n",
    "# Create search space parameters for latent dimensions\n",
    "parameters = []\n",
    "for i, (lower, upper) in enumerate(latent_bounds):\n",
    "    parameters.append({\n",
    "        \"name\": f\"latent_dim_{i}\",\n",
    "        \"type\": \"range\",\n",
    "        \"bounds\": [float(lower), float(upper)],\n",
    "        \"value_type\": \"float\"\n",
    "    })\n",
    "\n",
    "# Initialize Ax client\n",
    "ax_client = AxClient()\n",
    "ax_client.create_experiment(\n",
    "    name=\"molecular_latent_space_optimization\",\n",
    "    parameters=parameters,\n",
    "    objectives={\"qed_score\": ObjectiveProperties(minimize=False)}\n",
    ")\n",
    "\n",
    "print(\"Bayesian optimization setup complete!\")\n",
    "print(f\"Optimizing over {len(parameters)}D latent space\")\n",
    "print(f\"Objective: Maximize QED score (drug-likeness)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Training Data from Existing Molecules\n",
    "\n",
    "Before starting optimization, let's seed the Bayesian optimizer with some known molecules from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a few molecules as initial training data\n",
    "n_initial = 5\n",
    "initial_molecules = molecular_data.sample(n=n_initial, random_state=42)\n",
    "initial_latent = vae.encode(initial_molecules)\n",
    "\n",
    "print(f\"Adding {n_initial} initial molecules to training data:\")\n",
    "\n",
    "for i, (idx, mol) in enumerate(initial_molecules.iterrows()):\n",
    "    # Create parameter dict for this molecule\n",
    "    params = {\n",
    "        'latent_dim_0': initial_latent[i, 0],\n",
    "        'latent_dim_1': initial_latent[i, 1],\n",
    "        'latent_dim_2': initial_latent[i, 2]\n",
    "    }\n",
    "    \n",
    "    # Add trial to Ax\n",
    "    trial_index = ax_client.attach_trial(params)\n",
    "    ax_client.complete_trial(trial_index=trial_index, raw_data=mol['qed'])\n",
    "    \n",
    "    print(f\"Molecule {i+1}: QED = {mol['qed']:.3f}, MW = {mol['molecular_weight']:.1f}\")\n",
    "\n",
    "print(\"\\nInitial training data added to Bayesian optimizer.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Optimization Loop\n",
    "\n",
    "Now we'll run the main optimization loop, where the Bayesian optimizer suggests new latent space points to evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run optimization loop\n",
    "n_iterations = 15\n",
    "results = []\n",
    "\n",
    "print(f\"Starting Bayesian optimization for {n_iterations} iterations...\\n\")\n",
    "\n",
    "for iteration in range(n_iterations):\n",
    "    # Get next suggested trial\n",
    "    parameters, trial_index = ax_client.get_next_trial()\n",
    "    \n",
    "    # Evaluate the objective function\n",
    "    result = ax_objective_function(parameters)\n",
    "    qed_score = result[\"qed_score\"][0]\n",
    "    \n",
    "    # Complete the trial\n",
    "    ax_client.complete_trial(trial_index=trial_index, raw_data=qed_score)\n",
    "    \n",
    "    # Decode the latent point to see what molecule we're evaluating\n",
    "    latent_point = np.array([\n",
    "        parameters['latent_dim_0'],\n",
    "        parameters['latent_dim_1'],\n",
    "        parameters['latent_dim_2']\n",
    "    ]).reshape(1, -1)\n",
    "    \n",
    "    decoded_mol = vae.decode(latent_point).iloc[0]\n",
    "    \n",
    "    # Store results\n",
    "    results.append({\n",
    "        'iteration': iteration + 1,\n",
    "        'trial_index': trial_index,\n",
    "        'qed_score': qed_score,\n",
    "        'molecular_weight': decoded_mol['molecular_weight'],\n",
    "        'logp': decoded_mol['logp'],\n",
    "        'tpsa': decoded_mol['tpsa'],\n",
    "        'latent_0': parameters['latent_dim_0'],\n",
    "        'latent_1': parameters['latent_dim_1'],\n",
    "        'latent_2': parameters['latent_dim_2']\n",
    "    })\n",
    "    \n",
    "    print(f\"Iteration {iteration+1:2d}: QED = {qed_score:.3f}, \"\n",
    "          f\"MW = {decoded_mol['molecular_weight']:.1f}, \"\n",
    "          f\"LogP = {decoded_mol['logp']:.2f}, \"\n",
    "          f\"TPSA = {decoded_mol['tpsa']:.1f}\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(f\"\\nOptimization complete! Best QED score: {results_df['qed_score'].max():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Analysis\n",
    "\n",
    "Let's analyze the optimization results and visualize the progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot optimization progress\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# 1. QED score over iterations\n",
    "axes[0, 0].plot(results_df['iteration'], results_df['qed_score'], 'bo-', alpha=0.7)\n",
    "axes[0, 0].axhline(y=results_df['qed_score'].max(), color='r', linestyle='--', alpha=0.5, label='Best found')\n",
    "axes[0, 0].set_xlabel('Iteration')\n",
    "axes[0, 0].set_ylabel('QED Score')\n",
    "axes[0, 0].set_title('QED Score Optimization Progress')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Molecular weight distribution\n",
    "axes[0, 1].scatter(results_df['iteration'], results_df['molecular_weight'], \n",
    "                   c=results_df['qed_score'], cmap='viridis', alpha=0.7)\n",
    "axes[0, 1].set_xlabel('Iteration')\n",
    "axes[0, 1].set_ylabel('Molecular Weight')\n",
    "axes[0, 1].set_title('Molecular Weight vs QED Score')\n",
    "cbar1 = plt.colorbar(axes[0, 1].collections[0], ax=axes[0, 1])\n",
    "cbar1.set_label('QED Score')\n",
    "\n",
    "# 3. LogP vs TPSA colored by QED\n",
    "scatter = axes[1, 0].scatter(results_df['logp'], results_df['tpsa'], \n",
    "                            c=results_df['qed_score'], cmap='viridis', \n",
    "                            s=60, alpha=0.7)\n",
    "axes[1, 0].set_xlabel('LogP')\n",
    "axes[1, 0].set_ylabel('TPSA')\n",
    "axes[1, 0].set_title('Chemical Space Exploration (LogP vs TPSA)')\n",
    "cbar2 = plt.colorbar(scatter, ax=axes[1, 0])\n",
    "cbar2.set_label('QED Score')\n",
    "\n",
    "# 4. Latent space trajectory\n",
    "axes[1, 1].plot(results_df['latent_0'], results_df['latent_1'], 'bo-', alpha=0.5, markersize=4)\n",
    "# Color points by QED score\n",
    "scatter2 = axes[1, 1].scatter(results_df['latent_0'], results_df['latent_1'], \n",
    "                             c=results_df['qed_score'], cmap='viridis', s=60, alpha=0.8)\n",
    "axes[1, 1].set_xlabel('Latent Dimension 0')\n",
    "axes[1, 1].set_ylabel('Latent Dimension 1')\n",
    "axes[1, 1].set_title('Optimization Path in Latent Space')\n",
    "cbar3 = plt.colorbar(scatter2, ax=axes[1, 1])\n",
    "cbar3.set_label('QED Score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print best molecules found\n",
    "best_molecules = results_df.nlargest(3, 'qed_score')\n",
    "print(\"\\nTop 3 molecules found:\")\n",
    "print(\"=\" * 60)\n",
    "for i, mol in best_molecules.iterrows():\n",
    "    print(f\"Rank {i+1}: QED = {mol['qed_score']:.3f}\")\n",
    "    print(f\"  Molecular Weight: {mol['molecular_weight']:.1f}\")\n",
    "    print(f\"  LogP: {mol['logp']:.2f}\")\n",
    "    print(f\"  TPSA: {mol['tpsa']:.1f}\")\n",
    "    print(f\"  Latent coords: [{mol['latent_0']:.2f}, {mol['latent_1']:.2f}, {mol['latent_2']:.2f}]\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with Random Search\n",
    "\n",
    "Let's compare our Bayesian optimization results with random search to demonstrate the effectiveness of the approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random search comparison\n",
    "np.random.seed(42)\n",
    "n_random = len(results_df)\n",
    "random_results = []\n",
    "\n",
    "print(f\"Running random search with {n_random} evaluations...\")\n",
    "\n",
    "for i in range(n_random):\n",
    "    # Sample random point in latent space\n",
    "    random_latent = np.random.uniform(\n",
    "        low=[bound[0] for bound in latent_bounds],\n",
    "        high=[bound[1] for bound in latent_bounds],\n",
    "        size=vae.latent_dim\n",
    "    )\n",
    "    \n",
    "    # Evaluate\n",
    "    qed_score = molecular_objective_function(random_latent)\n",
    "    decoded_mol = vae.decode(random_latent.reshape(1, -1)).iloc[0]\n",
    "    \n",
    "    random_results.append({\n",
    "        'iteration': i + 1,\n",
    "        'qed_score': qed_score,\n",
    "        'molecular_weight': decoded_mol['molecular_weight'],\n",
    "        'logp': decoded_mol['logp'],\n",
    "        'tpsa': decoded_mol['tpsa']\n",
    "    })\n",
    "\n",
    "random_df = pd.DataFrame(random_results)\n",
    "\n",
    "# Plot comparison\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Cumulative best\n",
    "plt.subplot(1, 2, 1)\n",
    "bo_best = results_df['qed_score'].cummax()\n",
    "random_best = random_df['qed_score'].cummax()\n",
    "\n",
    "plt.plot(results_df['iteration'], bo_best, 'b-', label='Bayesian Optimization', linewidth=2)\n",
    "plt.plot(random_df['iteration'], random_best, 'r-', label='Random Search', linewidth=2)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Best QED Score Found')\n",
    "plt.title('Optimization Progress Comparison')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Distribution comparison\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(results_df['qed_score'], bins=10, alpha=0.7, label='Bayesian Optimization', color='blue')\n",
    "plt.hist(random_df['qed_score'], bins=10, alpha=0.7, label='Random Search', color='red')\n",
    "plt.xlabel('QED Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of QED Scores')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print comparison statistics\n",
    "print(\"\\nComparison Results:\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Bayesian Optimization:\")\n",
    "print(f\"  Best QED: {results_df['qed_score'].max():.3f}\")\n",
    "print(f\"  Mean QED: {results_df['qed_score'].mean():.3f}\")\n",
    "print(f\"  Std QED:  {results_df['qed_score'].std():.3f}\")\n",
    "\n",
    "print(f\"\\nRandom Search:\")\n",
    "print(f\"  Best QED: {random_df['qed_score'].max():.3f}\")\n",
    "print(f\"  Mean QED: {random_df['qed_score'].mean():.3f}\")\n",
    "print(f\"  Std QED:  {random_df['qed_score'].std():.3f}\")\n",
    "\n",
    "improvement = (results_df['qed_score'].max() - random_df['qed_score'].max()) / random_df['qed_score'].max() * 100\n",
    "print(f\"\\nImprovement: {improvement:.1f}% better best score with Bayesian optimization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion and Next Steps\n",
    "\n",
    "In this tutorial, we've demonstrated how to perform Bayesian optimization in molecular latent space. The key advantages of this approach include:\n",
    "\n",
    "### **What We Accomplished:**\n",
    "1. **Continuous Representation**: Encoded discrete molecules into a continuous latent space\n",
    "2. **Efficient Optimization**: Used Bayesian optimization to efficiently explore chemical space\n",
    "3. **Property Optimization**: Successfully optimized for drug-likeness (QED score)\n",
    "4. **Meaningful Results**: Found molecules with improved properties compared to random search\n",
    "\n",
    "### **Real-World Applications:**\n",
    "- **Drug Discovery**: Optimize ADMET properties, binding affinity, selectivity\n",
    "- **Materials Science**: Design polymers, catalysts, electronic materials\n",
    "- **Green Chemistry**: Find environmentally friendly alternatives\n",
    "- **Lead Optimization**: Improve existing drug candidates\n",
    "\n",
    "### **Extensions and Improvements:**\n",
    "1. **Better VAE Models**: Use more sophisticated molecular VAEs (JT-VAE, Grammar VAE, etc.)\n",
    "2. **Multi-objective Optimization**: Optimize multiple properties simultaneously (e.g., QED + synthetic accessibility)\n",
    "3. **Constraint Handling**: Add constraints for synthetic feasibility, toxicity, etc.\n",
    "4. **Active Learning**: Incorporate uncertainty quantification for more efficient exploration\n",
    "5. **Real Property Predictors**: Use trained models for ADMET, binding affinity, etc.\n",
    "\n",
    "### **Integration with SDL3 Workflows:**\n",
    "This approach fits naturally into Self-Driving Labs (SDL3) workflows:\n",
    "- **Design**: Latent space BO suggests molecular candidates\n",
    "- **Synthesis**: Automated synthesis of suggested molecules\n",
    "- **Characterization**: Automated property measurement\n",
    "- **Learning**: Feedback loop updates the optimization\n",
    "\n",
    "### **Key Takeaways:**\n",
    "- Latent space optimization bridges discrete molecular representations with continuous optimization\n",
    "- Bayesian optimization is significantly more efficient than random search for molecular design\n",
    "- The framework is flexible and can be adapted to various molecular properties and constraints\n",
    "- This approach is particularly powerful when combined with experimental automation (SDL3)\n",
    "\n",
    "The combination of generative models, latent space optimization, and automated experimentation represents a powerful paradigm for accelerating molecular discovery and materials science research."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}