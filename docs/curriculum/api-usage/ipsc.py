# Generated by Honegumi (https://arxiv.org/abs/2502.06815)
# %pip install ax-platform matplotlib
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from ax.modelbridge.factory import Models
from ax.modelbridge.generation_strategy import GenerationStep, GenerationStrategy
from ax.modelbridge.registry import ST_MTGP_trans
from ax.models.torch.botorch_modular.surrogate import ModelConfig, SurrogateSpec
from ax.service.ax_client import AxClient, ObjectiveProperties
from ax.service.utils.instantiation import FixedFeatures
from botorch.models.fully_bayesian_multitask import SaasFullyBayesianMultiTaskGP

# HACK: https://github.com/facebook/Ax/issues/3709

Specified_Task_ST_MTGP_trans = [
    item for item in ST_MTGP_trans if item.__name__ != "TrialAsTask"
]

obj1_name = "stemness"
obj2_name = "confluency"
obj3_name = "doubling_time"  # ASIDE: will probably treat as an outcome with an outcome constraint, since there'


def branin3_moo_mt(
    base1,
    supplement1,
    supplement2,
    c1,
    cell_type_task,
    dilution_volume=5.0,
    wellplate_position="A1",
):
    # dilution_volume: another way to represent this is you can check the number of cells and
    # then choose a dilution_volume based on a desired seeding density
    # wellplate_position: specifies the position in the wellplate (A1 to C4)
    # cell_type_task: specifies the cell type (heart or liver)
    y = float(
        (supplement1 - 5.1 / (4 * np.pi**2) * base1**2 + 5.0 / np.pi * base1 - 6.0) ** 2
        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(base1)
        + 10
    )

    # if multi-task, add a penalty based on cell type
    penalty_lookup = {"heart": 1.0, "liver": 1.1 + base1 + 2 * supplement1}
    y += penalty_lookup[cell_type_task]

    # Contrived way to incorporate supplement2 into the objective
    y = y * (1 + 0.1 * base1 * supplement1 * supplement2)

    # add a made-up penalty based on category
    penalty_lookup = {"A": 1.0, "B": 0.0, "C": 2.0}
    y += penalty_lookup[c1]  # second objective has base1 and supplement1 swapped
    y2 = float(
        (
            base1
            - 5.1 / (4 * np.pi**2) * supplement1**2
            + 5.0 / np.pi * supplement1
            - 6.0
        )
        ** 2
        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(supplement1)
        + 10
    )

    # if multi-task, add a penalty based on cell type for second objective
    penalty_lookup_2 = {"heart": 0.8, "liver": 0.9 + 2 * base1 + supplement1}
    y2 += penalty_lookup_2[cell_type_task]

    # Contrived way to incorporate supplement2 into the second objective
    y2 = y2 * (1 - 0.1 * base1 * supplement1 * supplement2)

    # add a made-up penalty based on category
    penalty_lookup = {"A": 0.0, "B": 2.0, "C": 1.0}
    y2 += penalty_lookup[c1]

    # Apply a mild effect based on wellplate position
    # Extract row (A, B, C) and column (1, 2, 3, 4) from wellplate_position
    row = wellplate_position[0]  # First character is the row
    col = int(wellplate_position[1:])  # Rest is the column number

    # Row effect: A slight gradient effect from row A to C (edge to center)
    row_effect = {"A": 0.95, "B": 1.0, "C": 1.05}
    # Column effect: Slight gradient from left to right
    col_effect = 1.0 + (col - 2.5) * 0.02  # -0.03 to +0.03 effect

    # Apply the positional effects to all objectives
    y *= row_effect[row] * col_effect
    y2 *= row_effect[row] * (1 / col_effect)  # Inverse effect on second objective

    # Calculate the third objective (doubling_time) based on other parameters
    y3 = float(
        3.0
        + 0.5 * base1
        + 0.3 * supplement1
        + 0.2 * supplement2
        + 0.1 * dilution_volume
    )

    # Apply task-specific modifications
    y3 *= 1.2 if cell_type_task == "liver" else 1.0

    # Add category-based adjustment
    category_factors = {"A": 1.1, "B": 0.9, "C": 1.0}
    y3 *= category_factors[c1]

    return {obj1_name: y, obj2_name: y2, obj3_name: y3}


# Define total for compositional constraint, where base1 + supplement1 + supplement2 == total
total = 10.0


# Define the training data

# note that for this training data, the compositional constraint is satisfied


X_train = pd.DataFrame(
    [
        {
            "base1": 4.0,
            "supplement1": 5.0,
            "cell_type_task": "heart",
            "supplement2": 1.0,
            "c1": "A",
        },
        {
            "base1": 0.0,
            "supplement1": 6.2,
            "cell_type_task": "liver",
            "supplement2": 3.8,
            "c1": "B",
        },
        {
            "base1": 5.9,
            "supplement1": 2.0,
            "cell_type_task": "heart",
            "supplement2": 2.0,
            "c1": "C",
        },
        {
            "base1": 1.5,
            "supplement1": 2.0,
            "cell_type_task": "liver",
            "supplement2": 6.5,
            "c1": "A",
        },
        {
            "base1": 1.0,
            "supplement1": 9.0,
            "cell_type_task": "heart",
            "supplement2": 0.0,
            "c1": "B",
        },
    ]
)

# Define y_train (normally the values would be supplied directly instead of calculating here)
y_train = [
    branin3_moo_mt(
        row["base1"],
        row["supplement1"],
        row["supplement2"],
        row["c1"],
        row["cell_type_task"],
    )
    for _, row in X_train.iterrows()
]

# See https://youtu.be/4tnaL9ts6CQ for simple human-in-the-loop BO instructions

# Define the number of training examples
n_train = len(X_train)

gs = GenerationStrategy(
    steps=[
        GenerationStep(
            model=Models.SOBOL,
            num_trials=8,  # how many sobol trials to perform (rule of thumb: 2 * number of params)
            min_trials_observed=3,
            max_parallelism=5,
            model_kwargs={"seed": 999, "transforms": Specified_Task_ST_MTGP_trans},
            # model_kwargs={"seed": 999, "transforms": MBM_MTGP_trans},
            model_gen_kwargs={"deduplicate": True},
        ),
        GenerationStep(
            model=Models.BOTORCH_MODULAR,
            num_trials=-1,
            max_parallelism=3,
            model_kwargs={
                "transforms": Specified_Task_ST_MTGP_trans,
                "surrogate_spec": SurrogateSpec(
                    model_configs=[
                        ModelConfig(botorch_model_class=SaasFullyBayesianMultiTaskGP)
                    ]
                ),
            },
        ),
    ]
)

ax_client = AxClient(generation_strategy=gs)

ax_client.create_experiment(
    parameters=[
        {"name": "base1", "type": "range", "bounds": [0.0, total]},
        {"name": "supplement1", "type": "range", "bounds": [0.0, total]},
        # dilution_volume: another way to represent this is you can check the number of cells and
        # then choose a dilution_volume based on a desired seeding density
        {"name": "dilution_volume", "type": "range", "bounds": [1.0, 10.0]},
        # wellplate_position: specifies the position in the wellplate (A1 to C4)
        {
            "name": "wellplate_position",
            "type": "choice",
            "values": [
                "A1",
                "A2",
                "A3",
                "A4",
                "B1",
                "B2",
                "B3",
                "B4",
                "C1",
                "C2",
                "C3",
                "C4",
            ],
        },
        {
            "name": "cell_type_task",
            "type": "choice",
            "values": ["heart", "liver"],
            "is_task": True,
            "target_value": "liver",
        },
        {
            "name": "c1",
            "type": "choice",
            "is_ordered": False,
            "values": ["A", "B", "C"],
        },
    ],
    objectives={
        obj1_name: ObjectiveProperties(minimize=True, threshold=25.0),
        obj2_name: ObjectiveProperties(minimize=True, threshold=15.0),
        obj3_name: ObjectiveProperties(
            minimize=True
        ),  # REVIEW: change to outcome and outcome constraint
    },
    parameter_constraints=[
        f"base1 + supplement1 <= {total}",  # reparameterized compositional constraint, which is a type of sum constraint
    ],
)

# Add existing data to the AxClient
for i in range(n_train):
    parameterization = X_train.iloc[i].to_dict()
    # remove supplement2, since it's hidden from search space due to composition constraint
    parameterization.pop("supplement2")

    # Add default values for the new parameters
    parameterization["dilution_volume"] = 5.0
    parameterization["wellplate_position"] = "A1"

    ax_client.attach_trial(parameterization)
    ax_client.complete_trial(trial_index=i, raw_data=y_train[i])


batch_size = 2  # in reality, likely at least 12, up to 12*8 (eight wellplates)


for i in range(5):  # Reduced from 23 to 5 iterations to run faster
    parameterizations, optimization_complete = ax_client.get_next_trials(
        batch_size,
        fixed_features=FixedFeatures(
            parameters={"cell_type_task": "heart" if i % 2 == 0 else "liver"}
        ),
    )
    for trial_index, parameterization in list(parameterizations.items()):
        base1 = float(parameterization["base1"])  # type: ignore (alternatively use custom safe_float fn)
        supplement1 = float(parameterization["supplement1"])  # type: ignore
        supplement2 = total - (base1 + supplement1)
        cell_type_task = parameterization["cell_type_task"]
        c1 = parameterization["c1"]
        dilution_volume = float(parameterization["dilution_volume"])  # type: ignore
        wellplate_position = str(parameterization["wellplate_position"])

        results = branin3_moo_mt(
            base1,
            supplement1,
            supplement2,
            c1,
            cell_type_task,
            dilution_volume,
            wellplate_position,
        )
        ax_client.complete_trial(trial_index=trial_index, raw_data=results)

# # Plot results
# objectives = ax_client.objective_names
# df = ax_client.get_trials_data_frame()

# fig, ax = plt.subplots(figsize=(6, 4), dpi=150)


# def get_pareto(df, cell_type="heart"):
#     t = df[df["cell_type_task"] == cell_type]
#     m = t.iloc[:, 4:6].values  # objectives are always cols 4,5
#     p = ~np.any(np.all(m[:, None] > m, axis=2), axis=1)
#     return [
#         (dict(r[df.columns[6:-1]]), dict(r[df.columns[4:6]]))
#         for i, r in t[p].iterrows()
#     ]


# cell_type = "heart"
# df_filtered = df[df.cell_type_task == cell_type]
# pareto = get_pareto(df, cell_type)
# pareto_data = [p[1] for p in pareto]
# pareto = pd.DataFrame(pareto_data).sort_values(objectives[0])

# ax.scatter(
#     df_filtered[objectives[0]],
#     df_filtered[objectives[1]],
#     fc="None",
#     ec="k",
#     label="Observed",
# )
# ax.plot(
#     pareto[objectives[0]],
#     pareto[objectives[1]],
#     color="#0033FF",
#     lw=2,
#     label="Pareto Front",
# )
# ax.set_title(f"Cell Type: {cell_type}")
# ax.set_xlabel(objectives[0])
# ax.set_ylabel(objectives[1])

# ax.legend()
# plt.show()
