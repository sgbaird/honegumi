{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a028469",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/sgbaird/honegumi/blob/main/docs/generated_notebooks/ax/objective-single%2Bmodel-Fully%20Bayesian%2Bcustom_gen-True%2Bexisting_data-True%2Bsum_constraint-False%2Border_constraint-False%2Blinear_constraint-True%2Bcomposition_constraint-True%2Bcategorical-True%2Bcustom_threshold-False%2Bsynchrony-batch.ipynb\"><img alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ebffe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ax-platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6fe0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ax.service.ax_client import AxClient, ObjectiveProperties\n",
    "\n",
    "from ax.modelbridge.factory import Models\n",
    "from ax.modelbridge.generation_strategy import GenerationStep, GenerationStrategy\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "obj1_name = \"branin\"\n",
    "\n",
    "\n",
    "def branin3(x1, x2, x3, c1):\n",
    "    y = float(\n",
    "        (x2 - 5.1 / (4 * np.pi**2) * x1**2 + 5.0 / np.pi * x1 - 6.0) ** 2\n",
    "        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x1)\n",
    "        + 10\n",
    "    )\n",
    "\n",
    "    # Contrived way to incorporate x3 into the objective\n",
    "    y = y * (1 + 0.1 * x1 * x2 * x3)\n",
    "\n",
    "    # add a made-up penalty based on category\n",
    "    penalty_lookup = {\"A\": 1.0, \"B\": 0.0, \"C\": 2.0}\n",
    "    y += penalty_lookup[c1]\n",
    "\n",
    "    return y\n",
    "\n",
    "\n",
    "# Define total for compositional constraint, where x1 + x2 + x3 == total\n",
    "total = 10.0\n",
    "\n",
    "\n",
    "# Define the training data\n",
    "\n",
    "# note that for this training data, the compositional constraint is satisfied\n",
    "\n",
    "\n",
    "X_train = pd.DataFrame(\n",
    "    [\n",
    "        {\"x1\": 4.0, \"x2\": 5.0, \"x3\": 1.0, \"c1\": \"A\"},\n",
    "        {\"x1\": 0.0, \"x2\": 6.2, \"x3\": 3.8, \"c1\": \"B\"},\n",
    "        {\"x1\": 5.9, \"x2\": 2.0, \"x3\": 2.0, \"c1\": \"C\"},\n",
    "        {\"x1\": 1.5, \"x2\": 2.0, \"x3\": 6.5, \"c1\": \"A\"},\n",
    "        {\"x1\": 1.0, \"x2\": 9.0, \"x3\": 0.0, \"c1\": \"B\"},\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define y_train (normally the values would be supplied directly instead of calculating here)\n",
    "y_train = [\n",
    "    branin3(row[\"x1\"], row[\"x2\"], row[\"x3\"], row[\"c1\"]) for _, row in X_train.iterrows()\n",
    "]\n",
    "\n",
    "# Define the number of training examples\n",
    "n_train = len(X_train)\n",
    "\n",
    "\n",
    "gs = GenerationStrategy(\n",
    "    steps=[\n",
    "        GenerationStep(\n",
    "            model=Models.SOBOL,\n",
    "            num_trials=8,  # https://github.com/facebook/Ax/issues/922\n",
    "            min_trials_observed=3,\n",
    "            max_parallelism=5,\n",
    "            model_kwargs={\"seed\": 999},\n",
    "            model_gen_kwargs={},\n",
    "        ),\n",
    "        GenerationStep(\n",
    "            model=Models.FULLYBAYESIAN,\n",
    "            num_trials=-1,\n",
    "            max_parallelism=3,\n",
    "            model_kwargs={},\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "ax_client = AxClient(generation_strategy=gs)\n",
    "# note how lower bound of x1 is now 0.0 instead of -5.0, which is for the sake of illustrating a composition, where negative values wouldn't make sense\n",
    "ax_client.create_experiment(\n",
    "    parameters=[\n",
    "        {\"name\": \"x1\", \"type\": \"range\", \"bounds\": [0.0, total]},\n",
    "        {\"name\": \"x2\", \"type\": \"range\", \"bounds\": [0.0, total]},\n",
    "        {\n",
    "            \"name\": \"c1\",\n",
    "            \"type\": \"choice\",\n",
    "            \"is_ordered\": False,\n",
    "            \"values\": [\"A\", \"B\", \"C\"],\n",
    "        },\n",
    "    ],\n",
    "    objectives={\n",
    "        obj1_name: ObjectiveProperties(minimize=True),\n",
    "    },\n",
    "    parameter_constraints=[\n",
    "        f\"x1 + x2 <= {total}\",  # reparameterized compositional constraint, which is a type of sum constraint\n",
    "        \"1.0*x1 + 0.5*x2 <= 15.0\",  # example of a linear constraint. Note the lack of space around the asterisks\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Add existing data to the AxClient\n",
    "for i in range(n_train):\n",
    "    parameterization = X_train.iloc[i].to_dict()\n",
    "\n",
    "    # remove x3, since it's hidden from search space due to composition constraint\n",
    "    parameterization.pop(\"x3\")\n",
    "\n",
    "    ax_client.attach_trial(parameterization)\n",
    "    ax_client.complete_trial(trial_index=i, raw_data=y_train[i])\n",
    "\n",
    "\n",
    "batch_size = 2\n",
    "\n",
    "\n",
    "for _ in range(23):\n",
    "\n",
    "    parameterizations, optimization_complete = ax_client.get_next_trials(batch_size)\n",
    "    for trial_index, parameterization in list(parameterizations.items()):\n",
    "        # extract parameters\n",
    "        x1 = parameterization[\"x1\"]\n",
    "        x2 = parameterization[\"x2\"]\n",
    "        x3 = total - (x1 + x2)  # composition constraint: x1 + x2 + x3 == total\n",
    "        c1 = parameterization[\"c1\"]\n",
    "\n",
    "        results = branin3(x1, x2, x3, c1)\n",
    "        ax_client.complete_trial(trial_index=trial_index, raw_data=results)\n",
    "\n",
    "\n",
    "best_parameters, metrics = ax_client.get_best_parameters()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
