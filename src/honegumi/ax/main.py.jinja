{% if existing_data or visualize %}
import numpy as np
import pandas as pd
from ax.service.ax_client import AxClient, ObjectiveProperties
{% if visualize %}import matplotlib.pyplot as plt{% endif %}
{% else %}
import numpy as np
from ax.service.ax_client import AxClient, ObjectiveProperties
{% endif %}

{# List of expected models #}
{% set expected_models = ["Default", "Custom", "Fully Bayesian"] %}

{# Check if model is in the list of expected models #}
{% if model not in expected_models %}
    {{ 0/0 }}
{% endif %}

{% if custom_gen -%}
from ax.modelbridge.factory import Models
from ax.modelbridge.generation_strategy import GenerationStep, GenerationStrategy
{%- endif %}
{% if model == "Custom" -%}
from botorch.acquisition import UpperConfidenceBound
{%- endif %}

{% if task == "Multi" -%}
from ax.modelbridge.registry import Specified_Task_ST_MTGP_trans
from ax.core.observation import ObservationFeatures
{%- endif %}

obj1_name = "branin"
{% if objective == "Multi" -%}
obj2_name = "branin_swapped"
{%- endif %}

def branin{% if composition_constraint %}3{% endif %}{% if objective == "Multi" %}_moo{% endif %}{% if task == "Multi" %}_mt{% endif %}(x1, x2{% if composition_constraint %}, x3{% endif %}{% if categorical %}, c1{% endif %}{% if task == "Multi" %}, task{% endif %}):
    y = float(
        (x2 - 5.1 / (4 * np.pi**2) * x1**2 + 5.0 / np.pi * x1 - 6.0) ** 2
        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x1)
        + 10
    )

    {% if task == "Multi" %}
    # if multi-task, add a penalty based on task
    penalty_lookup = {"A": 1.0, "B": 1.1 + x1 + 2*x2}
    y += penalty_lookup[task]
    {% endif %}

    {% if composition_constraint -%}
    # Contrived way to incorporate x3 into the objective
    y = y * (1 + 0.1 * x1 * x2 * x3)
    {%- endif %}

    {% if categorical %}
    # add a made-up penalty based on category
    penalty_lookup = {"A": 1.0, "B": 0.0, "C": 2.0}
    y += penalty_lookup[c1]
    {% endif %}
    {% if objective == "Multi" -%}
    # second objective has x1 and x2 swapped
    y2 = float(
        (x1 - 5.1 / (4 * np.pi**2) * x2**2 + 5.0 / np.pi * x2 - 6.0) ** 2
        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x2)
        + 10
    )
    {% if task == "Multi" %}
    # if multi-task, add a penalty based on task for second objective
    penalty_lookup_2 = {"A": 0.8, "B": 0.9 + 2*x1 + x2}
    y2 += penalty_lookup_2[task]
    {% endif %}

    {% if composition_constraint -%}
    # Contrived way to incorporate x3 into the second objective
    y2 = y2 * (1 - 0.1 * x1 * x2 * x3)
    {%- endif %}
    {% if categorical %}
    # add a made-up penalty based on category
    penalty_lookup = {"A": 0.0, "B": 2.0, "C": 1.0}
    y2 += penalty_lookup[c1]
    {% endif %}
    return {obj1_name: y, obj2_name: y2}
    {% else %} {# single objective #}
    return y
    {%- endif %}

{% set objective_function = "branin" %}

{% if composition_constraint -%}
    {% set objective_function = objective_function + "3" %}
{% endif %}

{# Set the objective function based on the objective #}
{% if objective == "Multi" -%}
    {% set objective_function = objective_function + "_moo" %}
{%- endif %}

{% if task == "Multi" %}
    {% set objective_function = objective_function + "_mt" %}
{% endif %}

{# add MOO to FULLYBAYESIAN if multi-objective #}
{% if model == "Fully Bayesian" and objective == "Multi" -%}
    {% set model_name = "FULLYBAYESIANMOO" %}
{% elif model == "Fully Bayesian" and objective != "Multi" -%}
    {% set model_name = "FULLYBAYESIAN" %}
{% else %}
    {% set model_name = "BOTORCH_MODULAR" %}
{%- endif %}

{% if composition_constraint %}
# Define total for compositional constraint, where x1 + x2 + x3 == total
total = 10.0
{% endif %}

{% if existing_data -%} {# categorical inline/repeated because will be clearer to readers #}
# Define the training data
{% if composition_constraint %}
# note that for this training data, the compositional constraint is satisfied
{% endif %}
{% if order_constraint %}
# note that for this training data, the order constraint is satisfied
{% endif %} {# TODO: REVIEW: consider how to incorporate out of design with the above scheme. Probably add an additional point that is for sure out of design and warn user if there are points like this? #}
{# Set some shorthand variables to make X_train more readable #}
{% set mt = task == "Multi"%}
{% set comp = composition_constraint %}
{% set cat = categorical %}
{% set ord = order_constraint %}
{# Note the lack of comma after x2, and the presence of a comma before the x3 #}
X_train = pd.DataFrame([
    {
        "x1": {% if comp %}4.0{% else %}-3.0{% endif %},
        "x2": 5.0
        {% if mt %}, "task": "A"{% endif %}
        {% if comp %},"x3": 1.0{% endif %}
        {% if cat %},"c1": "A"{% endif %}
    },
    {
        "x1": 0.0,
        "x2": 6.2
        {% if mt %}, "task": "B"{% endif %}
        {% if comp %},"x3": 3.8{% endif %}
        {% if cat %},"c1": "B"{% endif %}
    },
    {
        "x1": {% if ord %}2.1{% else %}5.9{% endif %},
        "x2": {% if ord %}5.9{% else %}2.0{% endif %}
        {% if mt %}, "task": "A"{% endif %}
        {% if comp %},"x3": 2.0{% endif %}
        {% if cat %},"c1": "C"{% endif %}
    },
    {
        "x1": 1.5,
        "x2": 2.0
        {% if mt %}, "task": "B"{% endif %}
        {% if comp %},"x3": 6.5{% endif %}
        {% if cat %},"c1": "A"{% endif %}
    },
    {
        "x1": 1.0,
        "x2": 9.0
        {% if mt %}, "task": "A"{% endif %}
        {% if comp %},"x3": 0.0{% endif %}
        {% if cat %},"c1": "B"{% endif %}
    }
])

# Define y_train (normally the values would be supplied directly instead of calculating here)
y_train = [
    {{ objective_function }}(
        row["x1"], 
        row["x2"]
        {% if composition_constraint %}, row["x3"]{% endif %}
        {% if categorical %}, row["c1"]{% endif %}
        {% if task == "Multi" %}, row["task"]{% endif %}
    ) 
    for _, row in X_train.iterrows()
]

# See https://youtu.be/4tnaL9ts6CQ for simple human-in-the-loop BO instructions

# Define the number of training examples
n_train = len(X_train)
{%- endif %}

{# Logic around the number of iterations #}
{# A reasonable default for initialization points is 2 * number of parameters #}
{% set num_init = 4 + 2 * (categorical + composition_constraint) if not dummy else 3 %}
{% set num_bayes = 15 if not dummy else 2 %}
{% set num_iter = num_init + num_bayes %}

{% if custom_gen -%}
gs = GenerationStrategy(
    steps=[
        GenerationStep(
            model=Models.SOBOL,
            num_trials={{ num_init }}, # how many sobol trials to perform (rule of thumb: 2 * number of params)
            min_trials_observed=3,
            max_parallelism=5,
            {% if task == "Multi" %}
            model_kwargs={"seed": 999, "transforms": Specified_Task_ST_MTGP_trans},
            model_gen_kwargs={"deduplicate": True},
            {% else %}
            model_kwargs={"seed": 999},
            {% endif %}
        ),
        GenerationStep(
            model=Models.{{ model_name }},
            num_trials=-1,
            max_parallelism=3,
            model_kwargs={% if task == "Multi" %}{% if model == "Fully Bayesian" %}{"num_samples": 512, "warmup_steps": 512, "transforms": Specified_Task_ST_MTGP_trans}{% elif model == "Custom" %}{"botorch_acqf_class": UpperConfidenceBound, "transforms": Specified_Task_ST_MTGP_trans}{% else %}{"transforms": Specified_Task_ST_MTGP_trans}{% endif %}{% elif model == "Fully Bayesian" %}{"num_samples": 512, "warmup_steps": 512}{% elif model == "Custom" %}{"botorch_acqf_class": UpperConfidenceBound}{% else %}{}{% endif %},
        ),
    ]
)
{%- endif %}

ax_client = AxClient({% if custom_gen %}generation_strategy=gs{% endif %})
{% if composition_constraint -%}
{%- endif %}
ax_client.create_experiment(
    parameters=[
        {"name": "x1", "type": "range", "bounds": {% if composition_constraint %}[0.0, total]{% else %}[-5.0, 10.0]{% endif %}},
        {"name": "x2", "type": "range", "bounds": {% if composition_constraint %}[0.0, total]{% else %}[0.0, 10.0]{% endif %}},
        {% if task == "Multi"%}
            {
                "name": "task",
                "type": "choice",
                "values": ["A", "B"],
                "is_task": True,
                "target_value": "B"
            }{% if categorical %},{% endif %}
        {% endif %}
        {% if categorical %}
            {
                "name": "c1",
                "type": "choice",
                "is_ordered": False,
                "values": ["A", "B", "C"]
            }
        {% endif %}
    ],
    objectives={
        obj1_name: ObjectiveProperties(minimize=True{% if custom_threshold %}, threshold=25.0{% endif %}),
{% if objective == "Multi" -%}
        obj2_name: ObjectiveProperties(minimize=True{% if custom_threshold %}, threshold=15.0{% endif %}),
{%- endif %}
    },
{% if sum_constraint or composition_constraint or order_constraint or linear_constraint %}
    parameter_constraints=[
        {% if sum_constraint %}
            {% if composition_constraint %}
                "x1 + x2 <= 15.0", # example of a sum constraint, which may be redundant/unintended if composition_constraint is also selected
            {% else %}
                "x1 + x2 <= 15.0", # example of a sum constraint
            {% endif %}
        {% endif %}
        {% if composition_constraint %}f"x1 + x2 <= {total}", # reparameterized compositional constraint, which is a type of sum constraint
        {% endif %}
        {% if order_constraint %}"x1 <= x2", # example of an order constraint
        {% endif %}
        {% if linear_constraint %}"1.0*x1 + 0.5*x2 <= 15.0", # example of a linear constraint. Note the lack of space around the asterisks
        {% endif %}
        ],
{% endif %}
)

{% if existing_data -%}
# Add existing data to the AxClient
for i in range(n_train):
    parameterization = X_train.iloc[i].to_dict()

    {% if composition_constraint %}
    # remove x3, since it's hidden from search space due to composition constraint
    parameterization.pop('x3')
    {% endif %}

    ax_client.attach_trial(parameterization)
    ax_client.complete_trial(trial_index=i, raw_data=y_train[i])
{%- endif %}
{# One BO step if dummy, TODO: change to 2+ if batch or asynchronous is selected #}
{% if synchrony == "Batch" %}
batch_size = 2
{% endif %}
{% set indent = "    " if synchrony == "Batch" else "" %}

for i in range({{ num_iter }}):
    {% if synchrony == "Single" and not task == "Multi" %}
    parameterization, trial_index = ax_client.get_next_trial()
    {% elif synchrony == "Single" and task == "Multi" %}
    parameterization, trial_index = ax_client.get_next_trial(fixed_features=ObservationFeatures({"task": "A" if i % 2 == 0 else "B"}))
    {% elif synchrony == "Batch" and task == "Multi" %}
    parameterization, trial_index = ax_client.get_next_trial(batch_size, fixed_features=ObservationFeatures({"task": "A" if i % 2 == 0 else "B"}))
    for trial_index, parameterization in list(parameterizations.items()):
    {% else %}
    parameterizations, optimization_complete = ax_client.get_next_trials(batch_size)
    for trial_index, parameterization in list(parameterizations.items()):
    {%- endif %}
    # extract parameters {# Consider using **parameters instead, but might require explanation and a link to ** docs #}
    {{ indent }}x1 = parameterization["x1"]
    {{ indent }}x2 = parameterization["x2"]
    {% if composition_constraint -%}
    {{ indent }}x3 = total - (x1 + x2) # composition constraint: x1 + x2 + x3 == total
    {%- endif %}
    {% if task == "Multi" %}
    {{ indent }}task = parameterization["task"]
    {%- endif %}
    {% if categorical -%}
    {{ indent }}c1 = parameterization["c1"]
    {%- endif %}

    {{ indent }}results = {{ objective_function }}(
    {{ indent }}    x1, x2{% if composition_constraint %}, x3{% endif %}{% if categorical %}, c1{% endif %}{% if task == "Multi" %}, task{% endif %}
    {{ indent }}    )
    {{ indent }}ax_client.complete_trial(trial_index=trial_index, raw_data=results)
{% if objective == "Multi" -%}
pareto_results = ax_client.get_pareto_optimal_parameters()
{% else %}
best_parameters, metrics = ax_client.get_best_parameters()
{%- endif %}

{% if visualize %}
# Plot results
objectives = ax_client.objective_names
df = ax_client.get_trials_data_frame()

{%- if task == "Multi" and objective == "Single" %}
task = "A"  # specify task results to plot
df = df[df.task == task]
{%- endif %}
{%- if synchrony == "Batch" %}
df.index = df.index // batch_size
best_to_trial = np.minimum.accumulate(df.groupby(df.index).min())
trials = df.index.unique()
{%- else %}
best_to_trial = np.minimum.accumulate(df)
trials = df.index
{%- endif %}

fig, ax = plt.subplots(figsize=(6, 4), dpi=150)

{%- if objective == "Single" %}
ax.scatter(df.index, df[objectives], ec="k", fc="none", label="Observed")
ax.plot(trials, best_to_trial[objectives], color="#0033FF", lw=2, label="Best to Trial")
{%- if task == "Multi" %}
ax.set_title(f"Task {task}")
{%- endif %}
ax.set_xlabel("Trial Number")
ax.set_ylabel(objectives[0])
{%- elif task != "Multi" %}
pareto = ax_client.get_pareto_optimal_parameters(use_model_predictions=False)
pareto_data = [p[1][0] for p in pareto.values()]
pareto = pd.DataFrame(pareto_data).sort_values(objectives[0])

ax.scatter(df[objectives[0]], df[objectives[1]], fc="None", ec="k", label="Observed")
ax.plot(pareto[objectives[0]], pareto[objectives[1]], color="#0033FF", lw=2, label="Pareto Front")

ax.set_xlabel(objectives[0])
ax.set_ylabel(objectives[1])
{%- endif %}

ax.legend()
plt.show()
{% endif %}
