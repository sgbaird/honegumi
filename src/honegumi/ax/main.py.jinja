import numpy as np
from ax.service.ax_client import AxClient, ObjectiveProperties

{% if custom_gen -%}
from ax.modelbridge.factory import Models
from ax.modelbridge.generation_strategy import GenerationStep, GenerationStrategy
{%- endif %}

{% if existing_data -%}
import pandas as pd
{%- endif %}

obj1_name = "branin"
{% if objective == "multi" -%}
obj2_name = "branin_swapped"
{%- endif %}

def branin{% if composition_constraint %}3{% endif %}{% if objective == "multi" %}_moo{% endif %}(x1, x2{% if composition_constraint %}, x3{% endif %}{% if categorical %}, c1{% endif %}):
    y = float(
        (x2 - 5.1 / (4 * np.pi**2) * x1**2 + 5.0 / np.pi * x1 - 6.0) ** 2
        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x1)
        + 10
    )

    {% if composition_constraint -%}
    # Contrived way to incorporate x3 into the objective
    y = y * (1 + 0.1 * x1 * x2 * x3)
    {%- endif %}

    {% if categorical %}
    # add a made-up penalty based on category
    penalty_lookup = {"A": 1.0, "B": 0.0, "C": 2.0}
    y += penalty_lookup[c1]
    {% endif %}
    {% if objective == "multi" -%}
    # second objective has x1 and x2 swapped
    y2 = float(
        (x1 - 5.1 / (4 * np.pi**2) * x2**2 + 5.0 / np.pi * x2 - 6.0) ** 2
        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x2)
        + 10
    )
    {% if composition_constraint -%}
    # Contrived way to incorporate x3 into the second objective
    y2 = y2 * (1 - 0.1 * x1 * x2 * x3)
    {%- endif %}
    {% if categorical %}
    # add a made-up penalty based on category
    penalty_lookup = {"A": 0.0, "B": 2.0, "C": 1.0}
    y2 += penalty_lookup[c1]
    {% endif %}
    return {obj1_name: y, obj2_name: y2}
    {% else %} {# single objective #}
    return y
    {%- endif %}

{% set objective_function = "branin" %}

{% if composition_constraint -%}
    {% set objective_function = objective_function + "3" %}
{% endif %}

{# Set the objective function based on the objective #}
{% if objective == "multi" -%}
    {% set objective_function = objective_function + "_moo" %}
{%- endif %}

{# List of expected models #}
{% set expected_models = ["Fully Bayesian", "Default"] %}

{# Check if model is in the list of expected models #}
{% if model not in expected_models %}
    {{ 0/0 }}
{% endif %}

{# add MOO to FULLYBAYESIAN if multi-objective #}
{% if model == "Fully Bayesian" and objective == "multi" -%}
    {% set model_name = "FULLYBAYESIANMOO" %}
{% elif model == "Fully Bayesian" and objective != "multi" -%}
    {% set model_name = "FULLYBAYESIAN" %}
{% else %}
    {% set model_name = "GPEI" %}
{%- endif %}

{% if composition_constraint %}
# Define total for compositional constraint, where x1 + x2 + x3 == total
total = 10.0
{% endif %}

{% if existing_data -%} {# categorical inline/repeated because will be clearer to readers #}
# Define the training data
{% if composition_constraint %}
# note that for this training data, the compositional constraint is satisfied
{% endif %}
{% if order_constraint %}
# note that for this training data, the order constraint is satisfied
{% endif %} {# TODO: REVIEW: consider how to incorporate out of design with the above scheme. Probably add an additional point that is for sure out of design and warn user if there are points like this? #}
{# Set some shorthand variables to make X_train more readable #}
{% set comp = composition_constraint %}
{% set cat = categorical %}
{% set ord = order_constraint %}
{# Note the lack of comma after x2, and the presence of a comma before the x3 #}
X_train = pd.DataFrame([
    {
        "x1": {% if comp %}4.0{% else %}-3.0{% endif %},
        "x2": 5.0
        {% if comp %},"x3": 1.0{% endif %}
        {% if cat %},"c1": "A"{% endif %}
    },
    {
        "x1": 0.0,
        "x2": 6.2
        {% if comp %},"x3": 3.8{% endif %}
        {% if cat %},"c1": "B"{% endif %}
    },
    {
        "x1": {% if ord %}2.1{% else %}5.9{% endif %},
        "x2": {% if ord %}5.9{% else %}2.0{% endif %}
        {% if comp %},"x3": 2.0{% endif %}
        {% if cat %},"c1": "C"{% endif %}
    },
    {
        "x1": 1.5,
        "x2": 2.0
        {% if comp %},"x3": 6.5{% endif %}
        {% if cat %},"c1": "A"{% endif %}
    },
    {
        "x1": 1.0,
        "x2": 9.0
        {% if comp %},"x3": 0.0{% endif %}
        {% if cat %},"c1": "B"{% endif %}
    }
])

# Define y_train (normally the values would be supplied directly instead of calculating here)
y_train = [{{ objective_function }}(row["x1"], row["x2"]{% if composition_constraint %}, row["x3"]{% endif %}{% if categorical %}, row["c1"]{% endif %}) for _, row in X_train.iterrows()]

# See https://youtu.be/4tnaL9ts6CQ for simple human-in-the-loop BO instructions

# Define the number of training examples
n_train = len(X_train)
{%- endif %}

{# Logic around the number of iterations #}
{# A reasonable default for initialization points is 2 * number of parameters #}
{% set num_init = 4 + 2 * (categorical + composition_constraint) if not dummy else 3 %}
{% set num_bayes = 15 if not dummy else 2 %}
{% set num_iter = num_init + num_bayes %}

{% if custom_gen -%}
gs = GenerationStrategy(
    steps=[
        GenerationStep(
            model=Models.SOBOL,
            num_trials={{ num_init }}, # https://github.com/facebook/Ax/issues/922
            min_trials_observed=3,
            max_parallelism=5,
            model_kwargs={"seed": 999},
            model_gen_kwargs={},
        ),
        GenerationStep(
            model=Models.{{ model_name }},
            num_trials=-1,
            max_parallelism=3,
            model_kwargs={{ model_kwargs }},
        ),
    ]
)
{%- endif %}

ax_client = AxClient({% if custom_gen %}generation_strategy=gs{% endif %})
{% if composition_constraint -%} # note how lower bound of x1 is now 0.0 instead of -5.0, which is for the sake of illustrating a composition, where negative values wouldn't make sense
{%- endif %}
ax_client.create_experiment(
    parameters=[
        {"name": "x1", "type": "range", "bounds": {% if composition_constraint %}[0.0, total]{% else %}[-5.0, 10.0]{% endif %}},
        {"name": "x2", "type": "range", "bounds": {% if composition_constraint %}[0.0, total]{% else %}[0.0, 10.0]{% endif %}},
        {% if categorical %}
                {
                    "name": "c1",
                    "type": "choice",
                    "is_ordered": False,
                    "values": ["A", "B", "C"]
                },
        {% endif %}
    ],
    objectives={
        obj1_name: ObjectiveProperties(minimize=True{% if custom_threshold %}, threshold=25.0{% endif %}),
{% if objective == "multi" -%}
        obj2_name: ObjectiveProperties(minimize=True{% if custom_threshold %}, threshold=15.0{% endif %}),
{%- endif %}
    },
{% if sum_constraint or composition_constraint or order_constraint or linear_constraint %}
    parameter_constraints=[
        {% if sum_constraint %}
            {% if composition_constraint %}
                "x1 + x2 <= 15.0", # example of a sum constraint, which may be redundant/unintended if composition_constraint is also selected
            {% else %}
                "x1 + x2 <= 15.0", # example of a sum constraint
            {% endif %}
        {% endif %}
        {% if composition_constraint %}f"x1 + x2 <= {total}", # reparameterized compositional constraint, which is a type of sum constraint
        {% endif %}
        {% if order_constraint %}"x1 <= x2", # example of an order constraint
        {% endif %}
        {% if linear_constraint %}"1.0*x1 + 0.5*x2 <= 15.0", # example of a linear constraint. Note the lack of space around the asterisks
        {% endif %}
        ],
{% endif %}
)

{% if existing_data -%}
# Add existing data to the AxClient
for i in range(n_train):
    parameterization = X_train.iloc[i].to_dict()

    {% if composition_constraint %}
    # remove x3, since it's hidden from search space due to composition constraint
    parameterization.pop('x3')
    {% endif %}

    ax_client.attach_trial(parameterization)
    ax_client.complete_trial(trial_index=i, raw_data=y_train[i])
{%- endif %}
{# One BO step if dummy, TODO: change to 2+ if batch or asynchronous is selected #}
{% if synchrony == "batch" %}
batch_size = 2
{% endif %}
{% set indent = "    " if synchrony == "batch" else "" %}
for _ in range({{ num_iter }}):
    {% if synchrony == "single" %}
    parameterization, trial_index = ax_client.get_next_trial()
    {% else %}
    parameterizations, optimization_complete = ax_client.get_next_trials(batch_size)
    for trial_index, parameterization in list(parameterizations.items()):
    {%- endif %}
    # extract parameters {# Consider using **parameters instead, but might require explanation and a link to ** docs #}
    {{ indent }}x1 = parameterization["x1"]
    {{ indent }}x2 = parameterization["x2"]
    {% if composition_constraint -%}
    {{ indent }}x3 = total - (x1 + x2) # composition constraint: x1 + x2 + x3 == total
    {%- endif %}
    {% if categorical -%}
    {{ indent }}c1 = parameterization["c1"]
    {%- endif %}

    {{ indent }}results = {{ objective_function }}(
    {{ indent }}    x1, x2{% if composition_constraint %}, x3{% endif %}{% if categorical %}, c1{% endif %}
    {{ indent }}    )
    {{ indent }}ax_client.complete_trial(trial_index=trial_index, raw_data=results)

{% if objective == "multi" -%}
pareto_results = ax_client.get_pareto_optimal_parameters()
{% else %}
best_parameters, metrics = ax_client.get_best_parameters()
{%- endif %}

{# CODE GRAVEYARD #}

{# {% if objective == "multi" -%}
obj1_name = "branin"
obj2_name = "neg_branin"

def branin_moo(x1, x2):
    """Multi-objective branin function

    The first objective is the normal branin value and the second
    objective is the negative branin value.
    """
    return {obj1_name: branin(x1, x2), obj2_name: -branin(x1, x2)}
{%- endif %} #}

{# # Calculate y_train using the objective function (didn't work due to not being able to execute Python code)
y_train = [
    {% for _, row in X_train.iterrows() %}
    {{ objective_function }}(row["x1"], row["x2"]{% if categorical %}, row["c1"]{% endif %}){% if not loop.last %}, {% endif %}
    {% endfor %}
] #}
